{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "A2_walk_through.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MCxqvFzvW3D0",
        "sYaehYOyVfr7",
        "ABfL37JwWOrT",
        "ndETYGh0jjEZ",
        "DQxcUbokWYHr",
        "9X1jBsp8b4Zh",
        "HhioxO9Vb7an",
        "E3OWMVgfWtsg"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCxqvFzvW3D0"
      },
      "source": [
        "# CISC 873 Data Mining - A2 - Speed Dating Match Prediction\n",
        "## Gavin McClelland - 15gm8 - 10211444\n",
        "### Due: Monday 18 October 2021, 23:59 EST\n",
        "\n",
        "⏰⚠ This notebook has been adapted from the provided template \"A2_walk_through.ipynb\"⚠⏰"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYaehYOyVfr7"
      },
      "source": [
        "# Task 1: Meme Competition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_pogI7BWJsE"
      },
      "source": [
        "This picture hits home for me as I typically use basic data visualizations in my progress reports at work.\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1lzYWZyW5U4YX2jk4ve3Yd6ciZjuD8mD-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABfL37JwWOrT"
      },
      "source": [
        "# Task 2: Understand the Template (Trial 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1LWexKkSAD3"
      },
      "source": [
        "import pandas as pd # importing pandas for dataframe operations\n",
        "import numpy as np # numpy for efficient array/math operations\n",
        "from sklearn.linear_model import LogisticRegression # baseline logreg model\n",
        "from sklearn.metrics import f1_score # evaluation metric to discern performance\n",
        "from pprint import pprint # used to print data structures in a readable format"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa0CO4UNSAEA",
        "outputId": "ea1018ee-5a25-4deb-84b1-7d3940691eac"
      },
      "source": [
        "data = pd.read_csv('/content/train.csv') # training split\n",
        "data_test = pd.read_csv('/content/test.csv') # testing split\n",
        "data.shape # prints the dimensions of the training split (5909 samples, )"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5909, 192)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mTheZB3pSAEE",
        "outputId": "9f486286-6080-433a-9f95-52619b943f72"
      },
      "source": [
        "# x-axis: bins containing number of null values\n",
        "# y-axis: number of columns with # of nulls in that bin\n",
        "# i.e. from figure, ~85 columns have 0-500 nulls/NaNs\n",
        "data.isnull().sum().hist()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5d00181790>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUIklEQVR4nO3df4xld1nH8fdjS2np4G5/4GSzbdwSGkjtSmFvakmNmWkpAjW2fzTYpsFFayZRQZQa2Woimmhc1IpYTXRjiWuyMq2lzWxKEOvSkZhIdQcK2x/UXeoWu5YdZX/gYCMuPv5xv7MOs3d3zt65P+Z7fb+SyT3ne8+553lmTz89851750RmIkmqz3cNuwBJUncMcEmqlAEuSZUywCWpUga4JFXq3EEe7NJLL81NmzZ1te83v/lNLrzwwt4WtIbYX91Gub9R7g3q6G9ubu7fM/M1y8cHGuCbNm1i7969Xe07OzvLxMREbwtaQ+yvbqPc3yj3BnX0FxEvdBp3CkWSKmWAS1KlDHBJqpQBLkmVMsAlqVIGuCRVygCXpEoZ4JJUKQNckio10E9irsa+Q8d5z7ZPDvy4B7ffPPBjSlITXoFLUqUMcEmqlAEuSZUywCWpUga4JFWqUYBHxC9ExNMR8VREfDwizo+IKyLiiYg4EBEPRMR5/S5WkvR/VgzwiNgI/BzQysyrgXOA24EPAx/JzNcBR4G7+lmoJOk7NZ1CORe4ICLOBV4FvATcADxUnt8J3Nr78iRJp7NigGfmIeB3ga/SDu7jwBxwLDNPlM1eBDb2q0hJ0qkiM8+8QcRFwCeAHwOOAX9J+8r718r0CRFxOfCpMsWyfP8pYApgfHx8y/T0dFeFzh85zuGXu9p1VTZvXDeQ4ywsLDA2NjaQYw2D/dVrlHuDOvqbnJycy8zW8vEmH6V/K/DPmflvABHxMHA9sD4izi1X4ZcBhzrtnJk7gB0ArVYru7156H27Zrh33+A/+X/wzomBHKeGG6uuhv3Va5R7g7r7azIH/lXguoh4VUQEcCPwDPA4cFvZZisw058SJUmdNJkDf4L2lMnngX1lnx3AB4EPRMQB4BLg/j7WKUlaptGcRGZ+CPjQsuHngWt7XpEkqRE/iSlJlTLAJalSBrgkVcoAl6RKGeCSVCkDXJIqZYBLUqUMcEmqlAEuSZUywCWpUga4JFXKAJekShngklQpA1ySKmWAS1KlDHBJqtSKAR4Rr4+IJ5d8fSMifj4iLo6IxyJif3m8aBAFS5LamtxS7bnMvCYzrwG2AP8JPAJsA/Zk5pXAnrIuSRqQs51CuRH4Sma+ANwC7CzjO4Fbe1mYJOnMIjObbxzxMeDzmfmHEXEsM9eX8QCOLq4v22cKmAIYHx/fMj093VWh80eOc/jlrnZdlc0b1w3kOAsLC4yNjQ3kWMNgf/Ua5d6gjv4mJyfnMrO1fLxxgEfEecC/At+XmYeXBnh5/mhmnnEevNVq5d69e8+y9Lb7ds1w775G92DuqYPbbx7IcWZnZ5mYmBjIsYbB/uo1yr1BHf1FRMcAP5splHfQvvo+XNYPR8SG8uIbgPnVlylJaupsAvwO4ONL1ncDW8vyVmCmV0VJklbWKMAj4kLgJuDhJcPbgZsiYj/w1rIuSRqQRpPKmflN4JJlY1+n/a4USdIQ+ElMSaqUAS5JlTLAJalSBrgkVcoAl6RKGeCSVCkDXJIqZYBLUqUMcEmqlAEuSZUywCWpUga4JFXKAJekShngklQpA1ySKmWAS1Klmt6RZ31EPBQRX46IZyPiLRFxcUQ8FhH7y+MZb2gsSeqtplfgHwX+KjPfALwReBbYBuzJzCuBPWVdkjQgKwZ4RKwDfgi4HyAzv5WZx4BbgJ1ls53Arf0qUpJ0qsjMM28QcQ2wA3iG9tX3HPB+4FBmri/bBHB0cX3Z/lPAFMD4+PiW6enprgqdP3Kcwy93teuqbN64biDHWVhYYGxsbCDHGgb7q9co9wZ19Dc5OTmXma3l400CvAV8Drg+M5+IiI8C3wDetzSwI+JoZp5xHrzVauXevXu7auC+XTPcu6/RPZh76uD2mwdynNnZWSYmJgZyrGGwv3qNcm9QR38R0THAm8yBvwi8mJlPlPWHgDcDhyNiQ3nxDcB8r4qVJK1sxQDPzK8B/xIRry9DN9KeTtkNbC1jW4GZvlQoSeqo6ZzE+4BdEXEe8DzwE7TD/8GIuAt4AXhXf0qUJHXSKMAz80nglPkX2lfjkqQh8JOYklQpA1ySKmWAS1KlDHBJqpQBLkmVMsAlqVIGuCRVygCXpEoZ4JJUKQNckiplgEtSpQxwSaqUAS5JlTLAJalSBrgkVarR3wOPiIPAfwDfBk5kZisiLgYeADYBB4F3ZebR/pQpSVrubK7AJzPzmiU31twG7MnMK4E9ZV2SNCCrmUK5BdhZlncCt66+HElSU00DPIG/joi5iJgqY+OZ+VJZ/how3vPqJEmnFZm58kYRGzPzUER8D/AY7Zsc787M9Uu2OZqZF3XYdwqYAhgfH98yPT3dVaHzR45z+OWudl2VzRvXDeQ4CwsLjI2NDeRYw2B/9Rrl3qCO/iYnJ+eWTF+f1PSmxofK43xEPAJcCxyOiA2Z+VJEbADmT7PvDmAHQKvVyomJia4auG/XDPfua1RuTx28c2Igx5mdnaXb700N7K9eo9wb1N3filMoEXFhRLx6cRl4G/AUsBvYWjbbCsz0q0hJ0qmaXNKOA49ExOL2f5GZfxUR/wg8GBF3AS8A7+pfmZKk5VYM8Mx8Hnhjh/GvAzf2oyhJ0sr8JKYkVcoAl6RKGeCSVCkDXJIqZYBLUqUMcEmqlAEuSZUywCWpUga4JFXKAJekShngklQpA1ySKmWAS1KlDHBJqpQBLkmVMsAlqVKNAzwizomIL0TEo2X9ioh4IiIORMQDEXFe/8qUJC13Nlfg7weeXbL+YeAjmfk64ChwVy8LkySdWaMAj4jLgJuBPy3rAdwAPFQ22Qnc2o8CJUmdRWauvFHEQ8BvAa8GfhF4D/C5cvVNRFwOfCozr+6w7xQwBTA+Pr5lenq6q0Lnjxzn8Mtd7boqmzeuG8hxFhYWGBsbG8ixhsH+6jXKvUEd/U1OTs5lZmv5+Io3NY6IHwHmM3MuIibO9sCZuQPYAdBqtXJi4qxfAoD7ds1w774Vy+25g3dODOQ4s7OzdPu9qYH91WuUe4O6+2uSiNcDPxoR7wTOB74b+CiwPiLOzcwTwGXAof6VKUlabsU58My8JzMvy8xNwO3AZzLzTuBx4Lay2VZgpm9VSpJOsZr3gX8Q+EBEHAAuAe7vTUmSpCbOalI5M2eB2bL8PHBt70uSJDXhJzElqVIGuCRVygCXpEoZ4JJUKQNckiplgEtSpQxwSaqUAS5JlTLAJalSBrgkVcoAl6RKGeCSVCkDXJIqZYBLUqUMcEmqlAEuSZVqclPj84HPAq8s2z+UmR+KiCuAadp345kD3p2Z3+pnsVK/bNr2yVXtf/fmE7yny9c4uP3mVR1b/381uQL/L+CGzHwjcA3w9oi4Dvgw8JHMfB1wFLirf2VKkpZrclPjzMyFsvqK8pXADcBDZXwncGtfKpQkdRSZufJGEefQniZ5HfBHwO8AnytX30TE5cCnMvPqDvtOAVMA4+PjW6anp7sqdP7IcQ6/3NWuq7J547qBHGdhYYGxsbGBHGsY1np/+w4dX9X+4xfQ9fk5qHOsW2v93261auhvcnJyLjNby8cb3dQ4M78NXBMR64FHgDc0PXBm7gB2ALRarZyYmGi663e4b9cM9+47q3sw98TBOycGcpzZ2Vm6/d7UYK331+389aK7N5/o+vwc1DnWrbX+b7daNfd3Vu9CycxjwOPAW4D1EbF4xl4GHOpxbZKkM1gxwCPiNeXKm4i4ALgJeJZ2kN9WNtsKzPSrSEnSqZr8zLcB2Fnmwb8LeDAzH42IZ4DpiPgN4AvA/X2sU5K0zIoBnplfAt7UYfx54Np+FCVJWpmfxJSkShngklQpA1ySKmWAS1KlDHBJqpQBLkmVMsAlqVIGuCRVygCXpEoZ4JJUKQNckiplgEtSpQxwSaqUAS5JlTLAJalSTe7Ic3lEPB4Rz0TE0xHx/jJ+cUQ8FhH7y+NF/S9XkrSoyRX4CeDuzLwKuA742Yi4CtgG7MnMK4E9ZV2SNCArBnhmvpSZny/L/0H7fpgbgVuAnWWzncCt/SpSknSqyMzmG0dsAj4LXA18NTMXb3YcwNHF9WX7TAFTAOPj41ump6e7KnT+yHEOv9zVrquyeeO6gRxnYWGBsbGxgRxrGNZ6f/sOHV/V/uMX0PX5OahzrFv9+Ldb7fe7W52+12v93ASYnJycy8zW8vHGAR4RY8DfAr+ZmQ9HxLGlgR0RRzPzjPPgrVYr9+7de5alt923a4Z79zW5B3NvHdx+80COMzs7y8TExECONQxrvb9N2z65qv3v3nyi6/NzUOdYt/rxb7fa73e3On2v1/q5CRARHQO80btQIuIVwCeAXZn5cBk+HBEbyvMbgPleFStJWlmTd6EEcD/wbGb+3pKndgNby/JWYKb35UmSTqfJz3zXA+8G9kXEk2Xsl4HtwIMRcRfwAvCu/pQoSepkxQDPzL8D4jRP39jbctaeQc3V3b35BO9Zdqy1Pjcqabj8JKYkVcoAl6RKGeCSVCkDXJIqZYBLUqUMcEmqlAEuSZUywCWpUga4JFXKAJekShngklQpA1ySKmWAS1KlDHBJqtTg71GmNa8ff0K305/L7cQ/oSs15xW4JFWqyS3VPhYR8xHx1JKxiyPisYjYXx7PeDNjSVLvNZlC+TPgD4E/XzK2DdiTmdsjYltZ/2Dvy5PUL02nyppOf2nwVrwCz8zPAkeWDd8C7CzLO4Fbe1yXJGkFkZkrbxSxCXg0M68u68cyc31ZDuDo4nqHfaeAKYDx8fEt09PTXRU6f+Q4h1/uatcqjF/AKf1t3rhuKLXsO3S856/Zqb9Oau25aX+drPWeV9PbWtPpe72wsMDY2NgQqmlucnJyLjNby8dX/S6UzMyIOO3/BTJzB7ADoNVq5cTERFfHuW/XDPfuG903zdy9+cQp/R28c2IotfTjx+VO/XVSa89N++tkrfe8mt7Wmk7f69nZWbrNpWHr9l0ohyNiA0B5nO9dSZKkJroN8N3A1rK8FZjpTTmSpKaavI3w48DfA6+PiBcj4i5gO3BTROwH3lrWJUkDtOLEVmbecZqnbuxxLZKks+AnMSWpUga4JFVqNN4bNKL68UelJI0Or8AlqVJegWtN8acOqTmvwCWpUga4JFXKAJekShngklQpA1ySKmWAS1KlDHBJqpQBLkmVMsAlqVJ+ElMaMj99qm55BS5JlVrVFXhEvB34KHAO8KeZ6Z15JK1ZnX7auXvzib7cyHupg9tv7svrdn0FHhHnAH8EvAO4CrgjIq7qVWGSpDNbzRTKtcCBzHw+M78FTAO39KYsSdJKIjO72zHiNuDtmflTZf3dwA9k5nuXbTcFTJXV1wPPdVnrpcC/d7lvDeyvbqPc3yj3BnX0972Z+Zrlg31/F0pm7gB2rPZ1ImJvZrZ6UNKaZH91G+X+Rrk3qLu/1UyhHAIuX7J+WRmTJA3AagL8H4ErI+KKiDgPuB3Y3ZuyJEkr6XoKJTNPRMR7gU/TfhvhxzLz6Z5VdqpVT8OscfZXt1Hub5R7g4r76/qXmJKk4fKTmJJUKQNckipVRYBHxNsj4rmIOBAR24ZdTxMR8bGImI+Ip5aMXRwRj0XE/vJ4URmPiPiD0t+XIuLNS/bZWrbfHxFbh9FLJxFxeUQ8HhHPRMTTEfH+Mj4SPUbE+RHxDxHxxdLfr5fxKyLiidLHA+UX+ETEK8v6gfL8piWvdU8Zfy4ifng4HZ0qIs6JiC9ExKNlfWR6A4iIgxGxLyKejIi9ZWwkzs+TMnNNf9H+BelXgNcC5wFfBK4adl0N6v4h4M3AU0vGfhvYVpa3AR8uy+8EPgUEcB3wRBm/GHi+PF5Uli8adm+ltg3Am8vyq4F/ov0nFUaix1LnWFl+BfBEqftB4PYy/sfAT5flnwH+uCzfDjxQlq8q5+wrgSvKuXzOsPsrtX0A+Avg0bI+Mr2V+g4Cly4bG4nz82Q/wy6gwT/CW4BPL1m/B7hn2HU1rH3TsgB/DthQljcAz5XlPwHuWL4dcAfwJ0vGv2O7tfQFzAA3jWKPwKuAzwM/QPsTe+eW8ZPnJu13Y72lLJ9btovl5+vS7Ybc02XAHuAG4NFS60j0tqSeTgE+UudnDVMoG4F/WbL+Yhmr0XhmvlSWvwaMl+XT9VhF7+VH6jfRvkodmR7LFMOTwDzwGO0rzGOZeaJssrTWk32U548Dl7B2+/t94JeA/ynrlzA6vS1K4K8jYq78SQ8YofMTvKHD0GRmRkT17+GMiDHgE8DPZ+Y3IuLkc7X3mJnfBq6JiPXAI8AbhlxST0TEjwDzmTkXERPDrqePfjAzD0XE9wCPRcSXlz5Z+/kJdfwSc5Q+sn84IjYAlMf5Mn66Htd07xHxCtrhvSszHy7DI9UjQGYeAx6nPa2wPiIWL3yW1nqyj/L8OuDrrM3+rgd+NCIO0v4rojfQ/rv+o9DbSZl5qDzO0/4f8LWM2PlZQ4CP0kf2dwOLv8XeSnveeHH8x8tvwq8Djpcf8z4NvC0iLiq/LX9bGRu6aF9q3w88m5m/t+SpkegxIl5TrryJiAtoz+8/SzvIbyubLe9vse/bgM9ke9J0N3B7eSfHFcCVwD8MpovOMvOezLwsMzfR/u/pM5l5JyPQ26KIuDAiXr24TPu8eooROT9PGvYkfMNfRryT9rscvgL8yrDraVjzx4GXgP+mPW92F+15wz3AfuBvgIvLtkH75hhfAfYBrSWv85PAgfL1E8Pua0ldP0h7jvFLwJPl652j0iPw/cAXSn9PAb9axl9LO6QOAH8JvLKMn1/WD5TnX7vktX6l9P0c8I5h97aszwn+710oI9Nb6eWL5evpxdwYlfNz8cuP0ktSpWqYQpEkdWCAS1KlDHBJqpQBLkmVMsAlqVIGuCRVygCXpEr9L32kOGhDozVFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "rZT0T8zvSAEF",
        "outputId": "ee2c0093-d762-40ca-812b-b154da0218de"
      },
      "source": [
        "# distribution of target attribute\n",
        "# highly imbalanced in favour of \"no match\" (~5:1 ratio)\n",
        "data['match'].hist()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5d00088250>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "zEgHz5FZSAEF",
        "outputId": "fcd8846f-3fe3-4f52-fb6f-9c9b09c3d55d"
      },
      "source": [
        "# down-grade scikit-learn (latest not greatest :) \n",
        "!pip install -Ivq scikit-learn==0.23.2\n",
        "\n",
        "# if you haven't installed xgboost on your system, uncomment the line below\n",
        "!pip install xgboost\n",
        "# if you haven't installed bayesian-optimization on your system, uncomment the line below\n",
        "!pip install scikit-optimize"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==0.23.2\n",
            "  Using cached scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "Collecting joblib>=0.11\n",
            "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "Collecting numpy>=1.13.3\n",
            "  Using cached numpy-1.21.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Using cached threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
            "Collecting scipy>=0.19.1\n",
            "  Using cached scipy-1.7.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n",
            "Installing collected packages: numpy, threadpoolctl, scipy, joblib, scikit-learn\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed joblib-1.1.0 numpy-1.21.2 scikit-learn-0.23.2 scipy-1.7.1 threadpoolctl-3.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "joblib",
                  "numpy",
                  "scipy",
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.2)\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (0.23.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.7.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yESsT3YGSAEG"
      },
      "source": [
        "x = data.drop('match', axis=1) # preparing features for training by removing target attribute\n",
        "features_numeric = list(x.select_dtypes(include=['float64'])) # get list of all numeric attributes\n",
        "features_categorical = list(x.select_dtypes(include=['object'])) # get list of all categorical attributes\n",
        "y = data['match'] # slice of all target attributes/results from training split"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmJjsI5zSAEH",
        "outputId": "b12f3a2d-d31c-49df-e548-9e52a2bafb9f"
      },
      "source": [
        "print(features_categorical) # printing the list of categorical features"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['field', 'undergra', 'mn_sat', 'tuition', 'from', 'zipcode', 'income', 'career']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB0cAu6tSAEI",
        "outputId": "a7837771-d020-4780-b878-501cdfe1f6ba"
      },
      "source": [
        "import numpy as np # already imported\n",
        "from sklearn.compose import ColumnTransformer # used to transform column(s) separate from the rest of the feature space\n",
        "# from sklearn.datasets import fetch_openml # fetches datasets from openml (i.e. iris dataset)\n",
        "from sklearn.pipeline import Pipeline # used to combine several transforms into a sequence of operations \n",
        "from sklearn.impute import SimpleImputer # imputation transformer, used for missing value replacement\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder # standard scaler used to convert numeric data to one-scale (would have been useful for last assignment), one hot is used for categorical encoding\n",
        "from sklearn.linear_model import LogisticRegression # already imported\n",
        "from sklearn.ensemble import RandomForestClassifier # ensemble classifier, fits several decision trees on several parameter combinations (bagging)\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV # method to create train and dev/validation splits, and GridSearch for parameter tuning \n",
        "from xgboost.sklearn import XGBClassifier # XGBoost classifier - faster, more accurate version of sklearn's GradientBoostingClassifier\n",
        "\n",
        "np.random.seed(0) # setting the random seed to yield repeatable results\n",
        "\n",
        "# transformer used to impute missing numeric values\n",
        "transformer_numeric = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')), # 1st step: impute missing values with the feature median\n",
        "        ('scaler', StandardScaler())] # 2nd step: convert feature to one scale (unit variance)\n",
        ")\n",
        "\n",
        "# transformer used to impute missing categorical values\n",
        "transformer_categorical = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')), # 1st step: replace missing values with literal 'missing'\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore')) # 2nd step: one-hot encodes features, creates a binary column for each category , encodes unknown categories as 0s\n",
        "    ]\n",
        ")\n",
        "\n",
        "# combines transformers pipelines into one transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', transformer_numeric, features_numeric), # 1st step: apply numeric transformer to numeric features\n",
        "        ('cat', transformer_categorical, features_categorical) # 2nd step: apply categorical transformer to numeric features\n",
        "    ]\n",
        ")\n",
        "\n",
        "# complete pipeline for a random forest classifier\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor), # 1st step: complete preprocessing transformer\n",
        "        # 2nd step: initialize random forest classifier (can use another classifier here, too, such as XGB)\n",
        "        ('my_classifier', \n",
        "           # XGBClassifier(objective='binary:logistic', seed=1), (another example)\n",
        "           RandomForestClassifier(), # using random forest for this example pipeline\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# `__` denotes attribute \n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`\n",
        "#  which is our xgb)\n",
        "\n",
        "# parameter grid used for GridSearch, hyperparameters supplied for both xgb and random forest\n",
        "param_grid = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'], # overwriting imputer strategy for numeric transformer \n",
        "    # 'my_classifier__n_estimators': [20, 30],  # this is for xgboost\n",
        "    # 'my_classifier__max_depth':[10, 20]       # this is for xgboost\n",
        "    'my_classifier__n_estimators': [20, 30, 40],    # this is for random forest\n",
        "    'my_classifier__max_depth':[10, 20, 30]         # this is for random forest\n",
        "}\n",
        "\n",
        "# exhaustive search over parameter grid using the complete pipeline for random forest, scored using ROC AUC\n",
        "grid_search = GridSearchCV(\n",
        "    full_pipline, param_grid, cv=3, verbose=1, n_jobs=2, # 3 validation folds, 2 jobs run in parallel\n",
        "    scoring='roc_auc')\n",
        "\n",
        "grid_search.fit(x, y) # run fit with all parameter sets (exhaustive since we're using grid search) \n",
        "\n",
        "print('best score {}'.format(grid_search.best_score_)) # best score from grid search\n",
        "print('best score {}'.format(grid_search.best_params_)) # best parameter set from grid search"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  27 out of  27 | elapsed:   19.7s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.840205007022898\n",
            "best score {'my_classifier__max_depth': 10, 'my_classifier__n_estimators': 40, 'preprocessor__num__imputer__strategy': 'mean'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "ASLOhP3PSAEZ",
        "outputId": "0f3f46a1-9246-46e9-9aa3-b831fd361cb7"
      },
      "source": [
        "# here we print the dataframe containing all of the results from gridsearch,\n",
        "# including the score on each split\n",
        "print('all the cv scores')\n",
        "pd.DataFrame(grid_search.cv_results_) # printing dataframe of all grid search results"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all the cv scores\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_my_classifier__max_depth</th>\n",
              "      <th>param_my_classifier__n_estimators</th>\n",
              "      <th>param_preprocessor__num__imputer__strategy</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.501835</td>\n",
              "      <td>0.013519</td>\n",
              "      <td>0.088846</td>\n",
              "      <td>0.004068</td>\n",
              "      <td>10</td>\n",
              "      <td>20</td>\n",
              "      <td>mean</td>\n",
              "      <td>{'my_classifier__max_depth': 10, 'my_classifie...</td>\n",
              "      <td>0.840741</td>\n",
              "      <td>0.823222</td>\n",
              "      <td>0.805865</td>\n",
              "      <td>0.823276</td>\n",
              "      <td>0.014238</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.658783</td>\n",
              "      <td>0.010809</td>\n",
              "      <td>0.099294</td>\n",
              "      <td>0.004515</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>mean</td>\n",
              "      <td>{'my_classifier__max_depth': 10, 'my_classifie...</td>\n",
              "      <td>0.843386</td>\n",
              "      <td>0.840192</td>\n",
              "      <td>0.827986</td>\n",
              "      <td>0.837188</td>\n",
              "      <td>0.006636</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.793568</td>\n",
              "      <td>0.015877</td>\n",
              "      <td>0.107466</td>\n",
              "      <td>0.003213</td>\n",
              "      <td>10</td>\n",
              "      <td>40</td>\n",
              "      <td>mean</td>\n",
              "      <td>{'my_classifier__max_depth': 10, 'my_classifie...</td>\n",
              "      <td>0.844557</td>\n",
              "      <td>0.844573</td>\n",
              "      <td>0.831485</td>\n",
              "      <td>0.840205</td>\n",
              "      <td>0.006166</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.959238</td>\n",
              "      <td>0.014963</td>\n",
              "      <td>0.086944</td>\n",
              "      <td>0.002331</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>mean</td>\n",
              "      <td>{'my_classifier__max_depth': 20, 'my_classifie...</td>\n",
              "      <td>0.803789</td>\n",
              "      <td>0.817159</td>\n",
              "      <td>0.800729</td>\n",
              "      <td>0.807226</td>\n",
              "      <td>0.007134</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.341841</td>\n",
              "      <td>0.040307</td>\n",
              "      <td>0.100758</td>\n",
              "      <td>0.001366</td>\n",
              "      <td>20</td>\n",
              "      <td>30</td>\n",
              "      <td>mean</td>\n",
              "      <td>{'my_classifier__max_depth': 20, 'my_classifie...</td>\n",
              "      <td>0.810470</td>\n",
              "      <td>0.815911</td>\n",
              "      <td>0.798970</td>\n",
              "      <td>0.808450</td>\n",
              "      <td>0.007062</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.711381</td>\n",
              "      <td>0.032169</td>\n",
              "      <td>0.114952</td>\n",
              "      <td>0.004864</td>\n",
              "      <td>20</td>\n",
              "      <td>40</td>\n",
              "      <td>mean</td>\n",
              "      <td>{'my_classifier__max_depth': 20, 'my_classifie...</td>\n",
              "      <td>0.833914</td>\n",
              "      <td>0.821931</td>\n",
              "      <td>0.811622</td>\n",
              "      <td>0.822489</td>\n",
              "      <td>0.009109</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.131955</td>\n",
              "      <td>0.020179</td>\n",
              "      <td>0.091288</td>\n",
              "      <td>0.000890</td>\n",
              "      <td>30</td>\n",
              "      <td>20</td>\n",
              "      <td>mean</td>\n",
              "      <td>{'my_classifier__max_depth': 30, 'my_classifie...</td>\n",
              "      <td>0.785802</td>\n",
              "      <td>0.811308</td>\n",
              "      <td>0.801220</td>\n",
              "      <td>0.799443</td>\n",
              "      <td>0.010488</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.581879</td>\n",
              "      <td>0.016834</td>\n",
              "      <td>0.103983</td>\n",
              "      <td>0.003717</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>mean</td>\n",
              "      <td>{'my_classifier__max_depth': 30, 'my_classifie...</td>\n",
              "      <td>0.811664</td>\n",
              "      <td>0.815706</td>\n",
              "      <td>0.793625</td>\n",
              "      <td>0.806998</td>\n",
              "      <td>0.009599</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.948391</td>\n",
              "      <td>0.139401</td>\n",
              "      <td>0.101186</td>\n",
              "      <td>0.015824</td>\n",
              "      <td>30</td>\n",
              "      <td>40</td>\n",
              "      <td>mean</td>\n",
              "      <td>{'my_classifier__max_depth': 30, 'my_classifie...</td>\n",
              "      <td>0.824210</td>\n",
              "      <td>0.819891</td>\n",
              "      <td>0.819687</td>\n",
              "      <td>0.821263</td>\n",
              "      <td>0.002086</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0       0.501835      0.013519  ...        0.014238                3\n",
              "1       0.658783      0.010809  ...        0.006636                2\n",
              "2       0.793568      0.015877  ...        0.006166                1\n",
              "3       0.959238      0.014963  ...        0.007134                7\n",
              "4       1.341841      0.040307  ...        0.007062                6\n",
              "5       1.711381      0.032169  ...        0.009109                4\n",
              "6       1.131955      0.020179  ...        0.010488                9\n",
              "7       1.581879      0.016834  ...        0.009599                8\n",
              "8       1.948391      0.139401  ...        0.002086                5\n",
              "\n",
              "[9 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "5DCaKKpdSAEc",
        "outputId": "8162887f-5d1b-4b84-dcc6-560fafe89c07"
      },
      "source": [
        "# prepare submission:\n",
        "submission = pd.DataFrame() # initializing df for recording submission scores\n",
        "submission['id'] = data_test['id'] # Series of samples for which predictions are being made\n",
        "submission['match'] = grid_search.predict_proba(data_test)[:,1] # use grid search to predict probability for each sample in test split\n",
        "submission.to_csv('sample_submission_walkthrough.csv', index=False) # generate submission csv for template\n",
        "submission # printing submission results dataframe"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>934</td>\n",
              "      <td>0.087602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6539</td>\n",
              "      <td>0.293644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6757</td>\n",
              "      <td>0.172368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2275</td>\n",
              "      <td>0.117874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1052</td>\n",
              "      <td>0.090979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2464</th>\n",
              "      <td>7982</td>\n",
              "      <td>0.165208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2465</th>\n",
              "      <td>7299</td>\n",
              "      <td>0.290775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2466</th>\n",
              "      <td>1818</td>\n",
              "      <td>0.086282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2467</th>\n",
              "      <td>937</td>\n",
              "      <td>0.106396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2468</th>\n",
              "      <td>6691</td>\n",
              "      <td>0.060121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2469 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id     match\n",
              "0      934  0.087602\n",
              "1     6539  0.293644\n",
              "2     6757  0.172368\n",
              "3     2275  0.117874\n",
              "4     1052  0.090979\n",
              "...    ...       ...\n",
              "2464  7982  0.165208\n",
              "2465  7299  0.290775\n",
              "2466  1818  0.086282\n",
              "2467   937  0.106396\n",
              "2468  6691  0.060121\n",
              "\n",
              "[2469 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsthDl8MSAEd",
        "outputId": "f1e64f67-e1a6-47ea-85a0-8b42b32cde12"
      },
      "source": [
        "from skopt import BayesSearchCV # bayesian optimization from scikit-optimize\n",
        "from skopt.space import Real, Categorical, Integer # supporting search space dimensions for integer, categorical, and float data \n",
        "from sklearn.svm import SVC # support vector classifier used for predicition\n",
        "\n",
        "# pipeline for SVC model\n",
        "SVC_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor), # 1st step: using same preprocessing pipeline as before\n",
        "        ('my_svc', SVC(class_weight='balanced')) # 2nd step: using an SVC model this time with balanced class weights\n",
        "    ]\n",
        ")\n",
        "# SVC has a class_weight attribute for unbalanced data\n",
        "\n",
        "\n",
        "# define ranges for bayes search\n",
        "bayes_search = BayesSearchCV(\n",
        "    SVC_pipline, # Using SVC pipeline for Bayesian Optimization\n",
        "    # bayes search parameter 'grid'\n",
        "    {\n",
        "        'my_svc__C': Real(1e-6, 1e+6, prior='log-uniform'), # sampling range for regularization parameter C, randomly sampled using log-uniform sampling\n",
        "        'my_svc__gamma': Real(1e-6, 1e+1, prior='log-uniform'), # sampling range for kernel coefficient gamma\n",
        "        'my_svc__degree': Integer(1,8), # sampling range for degree of different polynomial classifiers\n",
        "        'my_svc__kernel': Categorical(['linear', 'poly', 'rbf']), # different kernel types to try\n",
        "    },\n",
        "    n_iter=3, # here we're doing 3 iterations where parameters are sampled from the ranges in the specified grid for each iteration\n",
        "    random_state=0, # random seed used for parameters that are sampled from a uniform distribution (log-uniform in this case)\n",
        "    verbose=1, # verbosity just specifies how much information is printed\n",
        "    cv=3, # 3 folds\n",
        ")\n",
        "\n",
        "bayes_search.fit(x, y) # run bayes search as specified (3 iterations)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   23.6s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   24.5s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   22.8s finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BayesSearchCV(cv=3,\n",
              "              estimator=Pipeline(steps=[('preprocessor',\n",
              "                                         ColumnTransformer(transformers=[('num',\n",
              "                                                                          Pipeline(steps=[('imputer',\n",
              "                                                                                           SimpleImputer(strategy='median')),\n",
              "                                                                                          ('scaler',\n",
              "                                                                                           StandardScaler())]),\n",
              "                                                                          ['positin1',\n",
              "                                                                           'pid',\n",
              "                                                                           'int_corr',\n",
              "                                                                           'age_o',\n",
              "                                                                           'race_o',\n",
              "                                                                           'pf_o_att',\n",
              "                                                                           'pf_o_sin',\n",
              "                                                                           'pf_o_int',\n",
              "                                                                           'pf_o_fun',\n",
              "                                                                           'pf_o_amb',\n",
              "                                                                           'pf_o_sha',\n",
              "                                                                           'attr_o',\n",
              "                                                                           'sinc_o',\n",
              "                                                                           'intel_o',\n",
              "                                                                           'fun_o',\n",
              "                                                                           'amb_o',\n",
              "                                                                           'sh...\n",
              "              n_iter=3, random_state=0,\n",
              "              search_spaces={'my_svc__C': Real(low=1e-06, high=1000000.0, prior='log-uniform', transform='normalize'),\n",
              "                             'my_svc__degree': Integer(low=1, high=8, prior='uniform', transform='normalize'),\n",
              "                             'my_svc__gamma': Real(low=1e-06, high=10.0, prior='log-uniform', transform='normalize'),\n",
              "                             'my_svc__kernel': Categorical(categories=('linear', 'poly', 'rbf'), prior=None)},\n",
              "              verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SarTr9siSAEe",
        "outputId": "03d65f5b-5fc3-4d38-d2e4-c504d978bf0b"
      },
      "source": [
        "print('best score {}'.format(bayes_search.best_score_)) # best mean score from bayesian optimization on 3 splits \n",
        "print('best score {}'.format(bayes_search.best_params_)) # parameter set on model with best performance"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8307663023909514\n",
            "best score OrderedDict([('my_svc__C', 0.0012602593949011189), ('my_svc__degree', 8), ('my_svc__gamma', 2.285959941576884), ('my_svc__kernel', 'poly')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "BejYOdnaSAEe",
        "outputId": "df50fd36-8f24-4b52-d445-ec954a253776"
      },
      "source": [
        "print('all the cv scores')\n",
        "pd.DataFrame(bayes_search.cv_results_) # printing results after performing bayesian optimization"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all the cv scores\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_my_svc__C</th>\n",
              "      <th>param_my_svc__degree</th>\n",
              "      <th>param_my_svc__gamma</th>\n",
              "      <th>param_my_svc__kernel</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.106737</td>\n",
              "      <td>0.917023</td>\n",
              "      <td>1.751879</td>\n",
              "      <td>0.067378</td>\n",
              "      <td>2.35272</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0228543</td>\n",
              "      <td>poly</td>\n",
              "      <td>{'my_svc__C': 2.352718564818733, 'my_svc__degr...</td>\n",
              "      <td>0.827411</td>\n",
              "      <td>0.824873</td>\n",
              "      <td>0.826816</td>\n",
              "      <td>0.826367</td>\n",
              "      <td>0.001084</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.396458</td>\n",
              "      <td>0.741238</td>\n",
              "      <td>1.780116</td>\n",
              "      <td>0.056538</td>\n",
              "      <td>0.00126026</td>\n",
              "      <td>8</td>\n",
              "      <td>2.28596</td>\n",
              "      <td>poly</td>\n",
              "      <td>{'my_svc__C': 0.0012602593949011189, 'my_svc__...</td>\n",
              "      <td>0.835025</td>\n",
              "      <td>0.828426</td>\n",
              "      <td>0.828847</td>\n",
              "      <td>0.830766</td>\n",
              "      <td>0.003017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.663504</td>\n",
              "      <td>0.328870</td>\n",
              "      <td>0.922065</td>\n",
              "      <td>0.017950</td>\n",
              "      <td>2.20954</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000248877</td>\n",
              "      <td>linear</td>\n",
              "      <td>{'my_svc__C': 2.2095350994035026, 'my_svc__deg...</td>\n",
              "      <td>0.793909</td>\n",
              "      <td>0.785279</td>\n",
              "      <td>0.790757</td>\n",
              "      <td>0.789982</td>\n",
              "      <td>0.003565</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0       6.106737      0.917023  ...        0.001084                2\n",
              "1       6.396458      0.741238  ...        0.003017                1\n",
              "2       6.663504      0.328870  ...        0.003565                3\n",
              "\n",
              "[3 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndETYGh0jjEZ"
      },
      "source": [
        "## Answers to Initial Questions\n",
        "**What is the experimental protocol used and how was it carried out?**\n",
        "\n",
        "The experimental protocol or procedure used is as follows: First, data preprocessing measures use different strategies for missing value replacement for both numeric and categorical data. Next, a classifier is used to make predictions on the preprocessed dataset. Lastly, hyperparameters were tuned/optimized using different hyperparameter search algorithms (grid search for generating template submission, and bayes search on another classifier--worse performance). This procedure was carried out using pipelines from the scikit-learn API to perform steps in sequence to streamline procedures. Moreover, preprocessing was accomplished using column transformers.\n",
        "\n",
        "**How did we tune hyper-parameters in the template?**\n",
        "\n",
        "Hyperparameters were tuned using grid search for the template submission, testing an exhaustive parameter grid to discern the best performance from a set of parameters. Bayes search (or Bayesian Optimization) was used on another classifier (SVC), where parameters are randomly sampled from a distribution for each specified parameter range.\n",
        "\n",
        "**What is the search space and what is the criteria to determine good/bad hyper-parameters?**\n",
        "\n",
        "The search space is defined by the range of values for each parameter in the grid. The search space in the template is as follows:\n",
        "\n",
        "    param_grid = {\n",
        "    \n",
        "        'preprocessor__num__imputer__strategy': ['mean'], # overwriting imputer strategy for numeric transformer \n",
        "        # 'my_classifier__n_estimators': [20, 30],  # this is for xgboost\n",
        "        # 'my_classifier__max_depth':[10, 20]       # this is for xgboost\n",
        "        'my_classifier__n_estimators': [20, 30, 40],    # this is for random forest\n",
        "        'my_classifier__max_depth':[10, 20, 30]         # this is for random forest\n",
        "    }\n",
        "\n",
        "In the case of grid search, all combinations in the space are tested (exhaustive). In the case of random search, a fixed number of iterations are specified and random combinations of parameters from the search space are used in each iteration (this takes much less time). In Bayes search, or bayesian optimization, parameter combinations are selected based on a distribution from the grid for a specified number of iterations. \n",
        "\n",
        "The criteria used to identify good/bad hyperparameters is the performance metric, where good hyperparameters improve the performance, and bad parameters and parameter values hinder performance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQxcUbokWYHr"
      },
      "source": [
        "# Task 3: Problem Formulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koMvu0-zWo4L"
      },
      "source": [
        "In this problem, the objective is to predict whether two people will 'match' in a particular speed dating session. The input we are working with consists of a profile of each person in the session, and the output is the prediction of whether there is a successful match, or not (binary classification). AUROC (or ROCAUC) is used as the evaluation metric on the predictions since we are predicting probability of a match as opposed to class labels. The provided dataset has several missing values due to incomplete dating profiles. As such, this will require attention to different preprocessing measures to impute/replace missing values, along with categorical encoding to work with numeric features. After preprocessing, different models will be benchmarked to predict the probability of a successful match. The challenges will be to determine the optimal strategy for replacing missing values, as well as determining the optimal hyperparameters for each model. Three different search algorithms will be used for hyperparameter optimization (Grid Search, Random Search, and Bayesian Optimization). An ideal solution will effectively address these challenges by achieving a missing value replacement strategy that is representative of the dataset, and optimize hyperparameters so the most accurate predictions can be made. The impact of this ideal solution would be understanding the features that lead to successful matches. Moreover, this would create the opportunity to provide informative recommendations for future speed dating sessions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfUDjjURWplO"
      },
      "source": [
        "# Task 4: Model Tuning and Documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X1jBsp8b4Zh"
      },
      "source": [
        "## Trials 1-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMSDam-9wgPP"
      },
      "source": [
        "Thoughts and observations from trial 0 (template): The SVC model performs worse than the random forest classifier, but it uses a different search for optimization (Bayes instead of Grid). Note that the performance is already high (ROCAUC > 0.84), so in reference to the DS tuning life cycle, we should be focused on experimenting with different model architectures and tuning hyperparameters to optimize performance and leaderboard score, which we will do in the following trials.\n",
        "\n",
        "Plan for trials 1-3:\n",
        "In these trials, I will try 3 different optimization algorithms (grid search, random search, and bayes search) to tune hyperparameters for the random forest model. I will use similar search spaces and record observations in markdown after each trial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYFw0GCc9CdD"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# the following functions were adopted from the code in the template\n",
        "\n",
        "# function to try random search, used throughout notebook\n",
        "def rsearch(pipeline, parameters, model, itr=10):\n",
        "  # fits a parameter grid to a pipeline using 5 fold cross-validation, included\n",
        "  # option to increase number of iterations, which could be preferred for\n",
        "  # large parameter grids to reduce training time\n",
        "  rdm = RandomizedSearchCV(\n",
        "    pipeline, \n",
        "    parameters, \n",
        "    cv=5,\n",
        "    n_iter=itr, \n",
        "    verbose=3, # most descriptive output\n",
        "    n_jobs=2,\n",
        "    scoring='roc_auc'\n",
        "  )\n",
        "  rdm.fit(x, y)\n",
        "  print('best score {}'.format(rdm.best_score_))\n",
        "  print('best params {}'.format(rdm.best_params_))\n",
        "  # prepare submission:\n",
        "  submission = pd.DataFrame()\n",
        "  submission['id'] = data_test['id']\n",
        "  submission['match'] = rdm.predict_proba(data_test)[:,1]\n",
        "  # generate csv with naming convention based on function name\n",
        "  submission.to_csv(f'random_{model}.csv', index=False)\n",
        "\n",
        "# function to try bayes search, used throughout notebook \n",
        "def bsearch(pipeline, parameters, model, itr=10):\n",
        "  # Similarly to random search, fits a parameter grid to a pipeline using \n",
        "  # 5 fold cross-validation, included option to increase number of iterations,\n",
        "  # which could be preferred for large parameter grids to reduce training time\n",
        "  bys = BayesSearchCV(\n",
        "    pipeline, \n",
        "    parameters, \n",
        "    cv=5,\n",
        "    n_iter=itr, \n",
        "    verbose=3, \n",
        "    n_jobs=2,\n",
        "    scoring='roc_auc'\n",
        "  )\n",
        "  bys.fit(x, y)\n",
        "  print('best score {}'.format(bys.best_score_))\n",
        "  print('best params {}'.format(bys.best_params_))\n",
        "  # prepare submission:\n",
        "  submission = pd.DataFrame()\n",
        "  submission['id'] = data_test['id']\n",
        "  submission['match'] = bys.predict_proba(data_test)[:,1]\n",
        "  # generate csv with naming convention based on function name\n",
        "  submission.to_csv(f'bayes_{model}.csv', index=False)\n",
        "\n",
        "# function to try grid search, used throughout notebook \n",
        "def gsearch(pipeline, parameters, model):\n",
        "  # fits a parameter grid to a pipeline using 5 fold cross-validation using\n",
        "  # all exhaustive combinations from the parameter grid\n",
        "  grid = GridSearchCV(\n",
        "    pipeline, \n",
        "    parameters, \n",
        "    cv=5,\n",
        "    verbose=3, \n",
        "    n_jobs=2,\n",
        "    scoring='roc_auc'\n",
        "  )\n",
        "  grid.fit(x, y)\n",
        "  print('best score {}'.format(grid.best_score_))\n",
        "  print('best params {}'.format(grid.best_params_))\n",
        "  # prepare submission:\n",
        "  submission = pd.DataFrame()\n",
        "  submission['id'] = data_test['id']\n",
        "  submission['match'] = grid.predict_proba(data_test)[:,1]\n",
        "  # generate csv with naming convention based on function name\n",
        "  submission.to_csv(f'grid_{model}.csv', index=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTMei0q-lgvX",
        "outputId": "c8e0138a-4bb2-4eda-fcea-dd75f8111d0e"
      },
      "source": [
        "# creating a rf pipeline from the provided template\n",
        "rf_pipeline = Pipeline(\n",
        " steps=[\n",
        " ('preprocessor', preprocessor), # same preprocessing pipeline\n",
        " ('rf', RandomForestClassifier(random_state=0)) # random forest classifier with random seed set for repeatability\n",
        " ]\n",
        ")\n",
        "\n",
        "# using a wider range of parameters in this grid\n",
        "rf_params = {\n",
        " # trying different numeric imputation strategies, initial in template is 'median'\n",
        " # 'most_frequent' is the mode for a given feature\n",
        " 'preprocessor__num__imputer__strategy': ['mean','median', 'most_frequent'],\n",
        " # wider range for number of estimators in the ensemble\n",
        " 'rf__n_estimators': [10,20,30,40,50,100],\n",
        " # wider range for maximum tree depth\n",
        " 'rf__max_depth':[5,10,20,30,50],\n",
        " # trying different criteria for measuring impurity\n",
        " 'rf__criterion':['gini','entropy'],\n",
        " # varying the number of features to include when computing the best split\n",
        " 'rf__max_features':['auto','sqrt','log2'],\n",
        " # assigning balanced weights to each class to handle imbalanced target\n",
        " # subsample computes weights based on each bootstrap sample or 'bag' \n",
        " 'rf__class_weight':['balanced','balanced_subsample']\n",
        "}\n",
        "\n",
        "# since we have a more broad parameter grid, using twice as many iterations for\n",
        "# random search (20 instead of the default 10)\n",
        "rsearch(rf_pipeline, rf_params, 'RandomForest', 20)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:   22.9s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:  1.5min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8451373700179815\n",
            "best params {'rf__n_estimators': 50, 'rf__max_features': 'sqrt', 'rf__max_depth': 10, 'rf__criterion': 'entropy', 'rf__class_weight': 'balanced_subsample', 'preprocessor__num__imputer__strategy': 'mean'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLuG1sAF6OoU"
      },
      "source": [
        "Thoughts and observations for trial 1: I would have expected the number of estimators to be higher in the best configuration, but only 20 iterations were run on a broad parameter space, so 100 estimators might not have been in one of the configurations tested. Nonetheless, the performance is a slight improvement from the baseline in the template."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbdb5pbxlxsN",
        "outputId": "bdab506b-7f82-40f6-fd2c-0be38f3ff83d"
      },
      "source": [
        "# specifying a parameter grid for bayesian optimization\n",
        "rf_params_bayes = {\n",
        " # again, trying different imputation strategies\n",
        " 'preprocessor__num__imputer__strategy': Categorical(['mean','median', 'most_frequent']),\n",
        " # specifying lower and upper bound for number of estimators to consider\n",
        " 'rf__n_estimators': Integer(10,500),\n",
        " # same with max tree depth\n",
        " 'rf__max_depth': Integer(5,50),\n",
        " # different measures of impurity, max # of features to consider, and class weights\n",
        " 'rf__criterion': Categorical(['gini','entropy']),\n",
        " 'rf__max_features': Categorical(['auto','sqrt','log2']),\n",
        " 'rf__class_weight': Categorical(['balanced','balanced_subsample'])\n",
        "}\n",
        "\n",
        "# fit for 20 iterations\n",
        "bsearch(rf_pipeline, rf_params_bayes, 'RandomForest', 20)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   20.3s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   20.4s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.4min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   16.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:    7.6s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   35.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   34.5s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   29.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   17.8s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   52.5s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   13.8s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:    7.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   15.4s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:    4.5s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   54.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:    7.4s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   11.6s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   11.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.4min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.3min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8536083939994541\n",
            "best params OrderedDict([('preprocessor__num__imputer__strategy', 'mean'), ('rf__class_weight', 'balanced_subsample'), ('rf__criterion', 'entropy'), ('rf__max_depth', 5), ('rf__max_features', 'sqrt'), ('rf__n_estimators', 447)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIeRtAqr6aYv"
      },
      "source": [
        "Thoughts and observations for trial 2: Interesting that in only 20 trials, the values for number of estimators and max depth approached the minimum and maximum values. The development score is better than random search as well, likely since Bayes search is somewhat like an informed random search, where it keeps track of good/bad values. I will keep this in mind in subsequent trials when using grid search to narrow down the best parameters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUoH_C0s6auq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "930e45a0-f0a5-490c-c719-b99c043a4465"
      },
      "source": [
        "# specifying a parameter grid for grid search\n",
        "rf_params_grid = {\n",
        " 'preprocessor__num__imputer__strategy': ['mean','median', 'most_frequent'],\n",
        " 'rf__n_estimators': [10,20,30,40,50,100],\n",
        " 'rf__max_depth':[5,10,20,30,50],\n",
        "#  'rf__criterion':['gini','entropy'],\n",
        "#  'rf__max_features':['auto','sqrt','log2'],\n",
        " 'rf__class_weight':['balanced','balanced_subsample']\n",
        "}\n",
        "\n",
        "# exhaustive search over entire parameter grid\n",
        "# this takes much longer, so I reduced the parameter grid to focus\n",
        "# on optimizing the number of estimators and max tree depth\n",
        "gsearch(rf_pipeline, rf_params_grid, 'RandomForest')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=2)]: Done 508 tasks      | elapsed:  8.5min\n",
            "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed: 13.9min\n",
            "[Parallel(n_jobs=2)]: Done 900 out of 900 | elapsed: 16.5min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.850000812205933\n",
            "best params {'preprocessor__num__imputer__strategy': 'mean', 'rf__class_weight': 'balanced_subsample', 'rf__max_depth': 5, 'rf__n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMpsHADN6bN5"
      },
      "source": [
        "Thoughts and observations for trial 3: The performance is worse than the bayes search result, and the training time is significantly longer. Also, grid search is rigid, and does not have the ability to take on values in between specified parameter ranges, which is likely why Bayes search performed better. For example, the model reached a value of 447 for n_estimators in its best parameter set, which was not an explicitly specified value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhioxO9Vb7an"
      },
      "source": [
        "## Trials 4-8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJYESZRE6bnj"
      },
      "source": [
        "Overall thoughts for trials 1-3: Random search is much faster than grid search, and it is also faster than Bayes search. Moreover, random search yields results that are similar to both other searches, despite taking less time. This makes it easier to narrow down the types of parameter values that appear to work well before using grid search or Bayes search to achieve the absolute best set of parameters.\n",
        "\n",
        "Plan for trials 4-8: I will experiment with different model architectures using random search (less time intensive, and can prototype model architectures more quickly)\n",
        "\n",
        "In subsequent trials (9 & 10, or until performance appears to max out), I intend to select the two models that perform the best out of the five models selected and use grid search to see if I can improve performance from the random search results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FDakvefa0gr"
      },
      "source": [
        "# in this cell I create pipelines for the other models I wish to try\n",
        "\n",
        "# importing more models to try, KNN and decision tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# creating a pipeline for benchmarking logistic regression\n",
        "# note that each of these models use the same preprocessing pipeline for imputation and encoding\n",
        "lr_pipeline = Pipeline(\n",
        " steps=[\n",
        "  ('preprocessor', preprocessor),\n",
        "  ('logreg', LogisticRegression()) # base logistic regression to be tuned\n",
        " ]\n",
        ")\n",
        "\n",
        "# pipeline for benchmarking KNN\n",
        "knn_pipeline = Pipeline(\n",
        " steps=[\n",
        "  ('preprocessor', preprocessor),\n",
        "  ('knn', KNeighborsClassifier()) # base KNN to be tuned\n",
        " ]\n",
        ")\n",
        "\n",
        "# pipeline for benchmarking a decision tree classifier\n",
        "dt_pipeline = Pipeline(\n",
        " steps=[\n",
        "  ('preprocessor', preprocessor),\n",
        "  ('dt', DecisionTreeClassifier(random_state=0)) # base DT to be tuned, random seed set\n",
        " ]\n",
        ")\n",
        "\n",
        "# pipeline benchmarking a support vector classifier\n",
        "svc_pipeline = Pipeline(\n",
        "    steps=[\n",
        "     ('preprocessor', preprocessor), \n",
        "     # using an SVC model with balanced class weights\n",
        "     ('svc', SVC(class_weight='balanced', random_state=0, probability=True))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# pipeline for benchmarking an XGBoost classifier\n",
        "xgb_pipeline = Pipeline(\n",
        " steps=[\n",
        "  ('preprocessor', preprocessor),\n",
        "  # setting the objective function as logistic regression for binary classification\n",
        "  # outputs the probability as required for this task\n",
        "  ('xgb', XGBClassifier(objective='binary:logistic', seed=0)) # also set random seed\n",
        " ]\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6clZ9OuooIM"
      },
      "source": [
        "In each of the following cells, we specify a parameter grid and fit it with random search. If a parameter appears to max out, they will be tweaked to see if we can maximize performance. I will use random search as it is efficient for getting rapid feedback on model performance under different parameter configurations. For each parameter grid, we vary the imputation strategy for numeric data in the preprocessing pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3AXf4Ibq0HI",
        "outputId": "d265b9ec-9f27-4227-bcc5-a611095e9f5f"
      },
      "source": [
        "# starting with logistic regression, we try different regularization methods and\n",
        "# coefficients, optimization algorithms, max iterations for convergence, and\n",
        "# experiment with using balanced class weights\n",
        "lr_params = {\n",
        " 'preprocessor__num__imputer__strategy': ['mean','median','most_frequent'],\n",
        " 'logreg__penalty': ['l2'],\n",
        " 'logreg__C':[0.1,0.5,1,1.5],\n",
        " 'logreg__solver':['sag', 'saga'],\n",
        " 'logreg__max_iter':[100,300,600],\n",
        " 'logreg__class_weight':['balanced']\n",
        "}\n",
        "\n",
        "# use random search for testing different parameter grids\n",
        "rsearch(lr_pipeline, lr_params, 'logreg', 30) # using more iterations than default"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=2)]: Done 150 out of 150 | elapsed:  6.0min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8612655873344274\n",
            "best params {'preprocessor__num__imputer__strategy': 'median', 'logreg__solver': 'saga', 'logreg__penalty': 'l2', 'logreg__max_iter': 100, 'logreg__class_weight': 'balanced', 'logreg__C': 0.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5MZzA73r8CV"
      },
      "source": [
        "Thoughts and observations for trial 4: Logistic regression performs well across a broad parameter grid. This is my best development score so far Worth noting that the maximum number of iterations was reached for the lower values of max_iter, so higher values were added in subsequent attempts. Leaderboard score was 0.86323."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMot23cHrM2O",
        "outputId": "7a8411fd-56c5-4d5b-f22b-8a3826d357a2"
      },
      "source": [
        "# next we try KNN, where we vary the number of nearest neighbours, weight\n",
        "# functions used for prediction, algorithms used to compute nearest neighbours,\n",
        "# and the distance metric (either manhattan or Euclidean distance)\n",
        "knn_params = {\n",
        " 'preprocessor__num__imputer__strategy': ['mean','median','most_frequent'],\n",
        " 'knn__n_neighbors': [70,100,120,150],\n",
        "#  'knn__n_neighbors': [5,10,20,40,60,100],\n",
        " 'knn__weights':['uniform', 'distance'],\n",
        " 'knn__algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        " 'knn__p':[1,2]\n",
        "}\n",
        "\n",
        "# running knn for the default 10 iterations\n",
        "rsearch(knn_pipeline, knn_params, 'knn')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:  2.8min finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py:415: UserWarning: cannot use tree with sparse input: using brute force\n",
            "  warnings.warn(\"cannot use tree with sparse input: \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8206598047041174\n",
            "best params {'preprocessor__num__imputer__strategy': 'mean', 'knn__weights': 'uniform', 'knn__p': 2, 'knn__n_neighbors': 120, 'knn__algorithm': 'kd_tree'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhIeGlJor_qd"
      },
      "source": [
        "Thoughts and observations for trial 5: Across a broad parameter grid, KNN does not perform as well as the other options. However, it does perform reasonably well, and is quick to train. The first attempt performed the best with 100 neighbors, so subsequent attempts tried to use higher values until performance stopped improving. Leaderboard score was 0.83299, which could be worse, but I think other models would suit this problem better.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwOUMOdJrzg9",
        "outputId": "b8912ccf-6ddf-40ba-9089-2383f829574f"
      },
      "source": [
        "# I know I've already done a random forest classifier in the template,\n",
        "# but I thought it would be good to see the performance gap between an ensemble\n",
        "# and a single tree, varying most parameters as these are quick to train\n",
        "dt_params = {\n",
        " 'preprocessor__num__imputer__strategy': ['mean','median','most_frequent'],\n",
        " 'dt__criterion': ['gini','entropy'],\n",
        " 'dt__splitter': ['best','random'],\n",
        " 'dt__max_depth': [5,10,15,20],\n",
        " 'dt__min_samples_leaf': [1,2,3,5,10],\n",
        " 'dt__max_features': ['auto','sqrt','log2'],\n",
        " 'dt__class_weight': ['None','balanced']\n",
        "}\n",
        "\n",
        "# running random search using more parameters as the \n",
        "rsearch(dt_pipeline, dt_params, 'dt', 50)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    4.9s\n",
            "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:   19.3s\n",
            "[Parallel(n_jobs=2)]: Done 250 out of 250 | elapsed:   39.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.6960767565173208\n",
            "best params {'preprocessor__num__imputer__strategy': 'most_frequent', 'dt__splitter': 'best', 'dt__min_samples_leaf': 10, 'dt__max_features': 'auto', 'dt__max_depth': 20, 'dt__criterion': 'entropy', 'dt__class_weight': 'balanced'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oaf6HFXdsA6N"
      },
      "source": [
        "Thoughts and observations for trial 6: The performance of a single decision tree isn't very good, despite search a very broad parameter grid across 50 iterations. This could be due to the model overfitting to the training data and failing to generalize to the validation splits (high variance). This issue appears to be addressed by the ensemble models as they perform much better (>0.83 ROCAUC). I did not bother submitting these results to the public leaderboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HazTOfdpsmeI",
        "outputId": "ce0fec55-e27f-4c8c-cdf0-4d863c333c9b"
      },
      "source": [
        "# Next I'll try to optimize the support vector classifier from the provided template.\n",
        "# Here, I vary the regularization parameter C, polynomial degree, and kernel coefficient, gamma.\n",
        "# svc_params = {\n",
        "#     'svc__C': [0.001,0.0025,0.005,0.01],\n",
        "#     'svc__degree': [7,8,9,10],\n",
        "#     'svc__gamma': [1,2,3],\n",
        "#     'svc__kernel': ['poly'],\n",
        "#     'svc__max_iter':[1000]\n",
        "# }\n",
        "# rsearch(svc_pipeline, svc_params, 'svc')\n",
        "\n",
        "# define ranges for bayes search\n",
        "svc_params = {\n",
        "  'svc__C': Real(1e-6, 1e+6, prior='log-uniform'), # sampling range for regularization parameter C, randomly sampled using log-uniform sampling\n",
        "  'svc__gamma': Real(1e-6, 1e+1, prior='log-uniform'), # sampling range for kernel coefficient gamma\n",
        "  'svc__degree': Integer(1,8), # sampling range for degree of different polynomial classifiers\n",
        "  'svc__kernel': Categorical(['linear', 'poly', 'rbf']), # different kernel types to try\n",
        "}\n",
        "bsearch(svc_pipeline, svc_params, 'svc', 5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.8min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.1min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.8min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.1min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.1min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8401299424166243\n",
            "best params OrderedDict([('svc__C', 3.1468579713776803), ('svc__degree', 3), ('svc__gamma', 0.18336394419123478), ('svc__kernel', 'linear')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS6Xjll6smtg"
      },
      "source": [
        "Thoughts and observations for trial 7: I do not know why, but this did not appear to converge until a finite number of iterations were specified, even for one iteration. The score for random search on the parameter space above (now \"commented out\") was <0.60, so I tried bayesian optimization as outlined in the template to see if I could improve the score in the template, which was ~0.83, and still acheived a similar score here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkIgnCaUsQ_W",
        "outputId": "a07e06d7-bdbe-4b50-97e8-ab6b96f42566"
      },
      "source": [
        "# last and definitely not least, I'll try out XGBoost, which is commonly\n",
        "# known as a powerful and efficient version of sklearn's GradientBoostingClassifier()\n",
        "# For this trial, I'll start by varying the number of estimators and max tree depth\n",
        "# from the provided template\n",
        "xgb_params = {\n",
        " # attempt 1\n",
        "#  'preprocessor__num__imputer__strategy': ['mean','median','most_frequent'],\n",
        "#  'xgb__n_estimators': [20,30],\n",
        "#  'xgb__max_depth':[10,20]\n",
        "\n",
        " # attempt 2\n",
        "#  'preprocessor__num__imputer__strategy': ['mean','median','most_frequent'],\n",
        "#  'xgb__n_estimators': [30,50,100],\n",
        "#  'xgb__max_depth':[3,5,7,10]\n",
        "\n",
        " # attempt 3\n",
        " 'preprocessor__num__imputer__strategy': ['mean','median','most_frequent'],\n",
        " 'xgb__n_estimators': [100,200,500],\n",
        " 'xgb__max_depth':[5,7,10,15],\n",
        " 'xgb__subsample':[0.6,0.8,1],\n",
        " 'xgb__colsample_bytree':[0.5,1],\n",
        "}\n",
        "\n",
        "# starting with just 10 iterations as the performance should be good to begin with\n",
        "rsearch(xgb_pipeline, xgb_params, 'xgb')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  8.1min\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed: 11.6min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8813002047530043\n",
            "best params {'xgb__subsample': 1, 'xgb__n_estimators': 200, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.5, 'preprocessor__num__imputer__strategy': 'mean'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrH2OTgWsHFo"
      },
      "source": [
        "Thoughts and observations for trial 8: XGBoost is a powerful model in applied machine learning, and in this particular application it is clear to see why. The results for three attempts using random search across different parameter grids are listed below.\n",
        "*   attempt 1 - 0.866\n",
        "*   attempt 2 - 0.878\n",
        "*   attempt 3 - 0.881 (leaderboard score 0.88121)\n",
        "\n",
        "It is clear that tuning certain hyperparameters and increasing parameter ranges made a significant improvement on performance. Now that I have a decent idea of what parameter ranges I want to test using grid search to get a better score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEC3oDJ2b_cb"
      },
      "source": [
        "## Trials 9 & 10+\n",
        "\n",
        "General observations from trials 4-8: the models performing the best are xgboost and random forest, likely due to their respective applications of bagging and boosting, which improves the prediction accuracy on difficult samples. Logistic Regression also performs well, but the decision tree classifier and KNN models perform poorly, likely due to their simplicity. In the final trials, I will try to improve performance from my current best on the leaderboard (ROCAUC of 0.88121) using grid search with a parameter grid covering similar values to the current best. The hope here is that I can specify parameters than may perform better using knowledge from the current best obtained using random search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lnlSUaDISKP",
        "outputId": "bfa8c22b-3c39-458c-e001-96ec6e441133"
      },
      "source": [
        "rf_params_grid = {\n",
        " 'preprocessor__num__imputer__strategy': ['mean'],\n",
        " 'rf__n_estimators': [1000,1500,2000],\n",
        " 'rf__max_depth':[5,6,7,8],\n",
        "#  'rf__n_estimators': [100],\n",
        "#  'rf__max_depth':[5],\n",
        "#  'rf__criterion':['gini','entropy'],\n",
        " 'rf__criterion':['entropy'],\n",
        "#  'rf__max_features':['auto','sqrt','log2'],\n",
        " 'rf__max_features':['auto'],\n",
        "#  'rf__class_weight':['balanced','balanced_subsample']\n",
        " 'rf__class_weight':['balanced_subsample']\n",
        "}\n",
        "\n",
        "gsearch(rf_pipeline, rf_params_grid, 'RandomForest')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=2)]: Done  60 out of  60 | elapsed: 11.7min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.854856568464361\n",
            "best params {'preprocessor__num__imputer__strategy': 'mean', 'rf__class_weight': 'balanced_subsample', 'rf__criterion': 'entropy', 'rf__max_depth': 7, 'rf__max_features': 'auto', 'rf__n_estimators': 1000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUapHiCKjFVa"
      },
      "source": [
        "Thoughts and observations for trial 9: This took 11 minutes and marginally improved performance. Still worse than the logistic regression score from random search in trial 4. Note that a few attempts were tried here, with certain features 'commented out' to reduce training time when exhaustively evaluating different parameters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYLuejoKIJ44",
        "outputId": "f9d516a7-5476-4fb4-9faf-9140e435db9a"
      },
      "source": [
        "# using the best parameters from the random search result, I'll continue to\n",
        "# vary parameter values around the best observed to see if there's any improvement\n",
        "# to performance that can be made\n",
        "lr_params = {\n",
        " 'preprocessor__num__imputer__strategy': ['mean','median'],\n",
        " 'logreg__penalty': ['l2'],\n",
        " 'logreg__C':[0.1,0.5,1,1.5],\n",
        " 'logreg__solver':['sag', 'saga'],\n",
        " 'logreg__max_iter':[100,300,600]\n",
        "}\n",
        "\n",
        "gsearch(lr_pipeline, lr_params, 'logreg')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:   37.4s\n",
            "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=2)]: Done 240 out of 240 | elapsed: 11.1min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8617489714479302\n",
            "best params {'logreg__C': 0.1, 'logreg__max_iter': 600, 'logreg__penalty': 'l2', 'logreg__solver': 'sag', 'preprocessor__num__imputer__strategy': 'median'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB6aeS24jHew"
      },
      "source": [
        "Thoughts and observations for trial 10: This is roughly the same as the results obtained using random search, and did not approach the xgboost score obtained using random search either, so I will focus on improving xgboost to improve my leaderboard score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCtiOkTdIoAC",
        "outputId": "e60aad51-5d89-4515-8fab-b33dfebf850d"
      },
      "source": [
        "xgb_params = {\n",
        "# config 1\n",
        "#  'preprocessor__num__imputer__strategy': ['mean','median','most_frequent'],\n",
        "# #  'xgb__n_estimators': [165,200,500,1000],\n",
        "# #  'xgb__max_depth':[10,15,20],\n",
        "#  'xgb__n_estimators': [165],\n",
        "#  'xgb__max_depth':[10],\n",
        "#  'xgb__eta':[0.05,0.1,0.3,0.5],\n",
        "#  'xgb__gamma':[0,1]\n",
        "\n",
        "# config 2\n",
        " 'preprocessor__num__imputer__strategy': ['mean'],\n",
        " 'xgb__n_estimators': [100,500],\n",
        " 'xgb__max_depth':[3,5,7],\n",
        " 'xgb__subsample':[0.6,0.8,1],\n",
        " 'xgb__colsample_bytree':[0.5,1]\n",
        "}\n",
        "\n",
        "gsearch(xgb_pipeline, xgb_params, 'xgb')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed: 13.6min\n",
            "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed: 27.7min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8829929982253713\n",
            "best params {'preprocessor__num__imputer__strategy': 'mean', 'xgb__colsample_bytree': 1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100, 'xgb__subsample': 0.8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrGzHSRGjKDv"
      },
      "source": [
        "Thoughts and observations for trial 11: While the validation score was marginally higher here, the score on the leaderboard remained unchanged at 0.88121. I feel like there is still room to grow as many others are performing better than I on the leaderboard, so I will try Bayes search to see if it improves anything. This also takes ~27 minutes, which is expensive compared to random search (11 minutes, fewer fits, similar score)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRmrpZr3jbbH",
        "outputId": "9c30d463-7794-4d5c-fd76-f2b75f6e1b7a"
      },
      "source": [
        "# trying to use reasonable parameter ranges for Bayes search so it does not take too long to fit\n",
        "# starting with only a few iterations and will increase if training time is reasonable\n",
        "xgb_params_bayes = {\n",
        " 'preprocessor__num__imputer__strategy': Categorical(['mean']),\n",
        " 'xgb__n_estimators': Integer(100,1000),\n",
        " 'xgb__max_depth': Integer(3,10),\n",
        " 'xgb__subsample':Real(0.6,1,prior='log-uniform'),\n",
        " 'xgb__colsample_bytree':Real(0.5,1,prior='log-uniform'),\n",
        " 'xgb__learning_rate':Real(0.01,0.3,prior='log-uniform')\n",
        "}\n",
        "\n",
        "bsearch(xgb_pipeline, xgb_params_bayes, 'xgb', 10)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.1min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  4.6min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.0min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   53.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.3min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.1min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.3min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  5.5min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.4min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.3min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8855199265879511\n",
            "best params OrderedDict([('preprocessor__num__imputer__strategy', 'mean'), ('xgb__colsample_bytree', 0.8061016730631486), ('xgb__learning_rate', 0.010960269022396139), ('xgb__max_depth', 10), ('xgb__n_estimators', 932), ('xgb__subsample', 0.8093813190151469)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkAPxwJCaVlD",
        "outputId": "46026791-3380-4504-f273-24f495c5ecde"
      },
      "source": [
        "bsearch(xgb_pipeline, xgb_params_bayes, 'xgb', 20)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   55.3s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.5min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.3min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.6min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   17.5s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   42.4s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   43.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.4min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.2min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   32.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  4.5min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   38.7s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.9min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.3min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   28.9s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.3min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  6.5min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.8min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8862182180837912\n",
            "best params OrderedDict([('preprocessor__num__imputer__strategy', 'mean'), ('xgb__colsample_bytree', 0.9987311362945805), ('xgb__learning_rate', 0.025624224805489117), ('xgb__max_depth', 8), ('xgb__n_estimators', 628), ('xgb__subsample', 0.7970432814408283)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oA5k3oZreOD",
        "outputId": "be03225a-b801-4318-c8bf-13b7b74221f1"
      },
      "source": [
        "bsearch(xgb_pipeline, xgb_params_bayes, 'xgb', 30)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.8min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.1min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.4min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.8min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  4.9min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   43.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.4min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.0min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.1min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.9min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   44.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  4.3min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.2min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.8min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:    8.7s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   17.6s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.1min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:    8.4s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   27.5s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.4min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.7min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.7min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.4min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   25.8s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   31.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.0min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.2min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   46.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.2min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.2min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8871534708933785\n",
            "best params OrderedDict([('preprocessor__num__imputer__strategy', 'mean'), ('xgb__colsample_bytree', 0.6653292249922945), ('xgb__learning_rate', 0.015787198787400956), ('xgb__max_depth', 6), ('xgb__n_estimators', 678), ('xgb__subsample', 0.7048257272210133)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVjrvSXX5qbS",
        "outputId": "ae96e0b5-5fb7-406b-d71a-44e4cede585a"
      },
      "source": [
        "bsearch(xgb_pipeline, xgb_params_bayes, 'xgb', 50)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   37.5s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.9min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.8min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.4min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.2min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.0min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   47.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.6min finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.5min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.7min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   11.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   40.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.1min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.2min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.3min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   33.9s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   59.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.1min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   14.4s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.2min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   27.5s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.0min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   11.6s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.1min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   37.4s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.1min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   22.5s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.7min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   58.9s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  5.2min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.5min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.8min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.9min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.6min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   12.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   19.6s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.1min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  4.0min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.8min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.4min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.4min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  4.0min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.2min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.9min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  3.9min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   10.7s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   16.5s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  4.3min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   50.4s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8861362585953232\n",
            "best params OrderedDict([('preprocessor__num__imputer__strategy', 'mean'), ('xgb__colsample_bytree', 0.9868045456137382), ('xgb__learning_rate', 0.01066217981695402), ('xgb__max_depth', 8), ('xgb__n_estimators', 1000), ('xgb__subsample', 0.9358180535704819)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFcHYu3IsGAS"
      },
      "source": [
        "Final Trial Results (all using same parameter grid):\n",
        "*   10 iterations: 0.88514 <-- best yet (leaderboard score of 0.88563! Currently 6th 🔥)\n",
        "*   10 iterations (again): leaderboard score of 0.88743 (now 4th on the leaderboard! 🔥🔥)\n",
        "*   20 iterations: best score of 0.88622 (leaderboard score of 0.88682, which is lower than my best)\n",
        "*   30 iterations: best score of 0.88715 (leaderboard score of 0.88953! Now in 3rd place! 🔥🔥🔥🔥🔥🔥🔥🔥🔥)\n",
        "*   50 iterations: best score of 0.88613 (lower than best development score)\n",
        "\n",
        "Final thoughts: 10 iterations of Bayes search takes roughly the same amount of time as grid search, but it can search a much broader parameter space. Moreover, it improved my score by increasing the number of iterations. However, I feel like the performance doesn't always improve with the number of iterations due to getting stuck in local maxima when searching the parameter range. Nonetheless, this approach (XGBoost + Bayes) helped me achieve my best score on the leaderboard, and improved the performance of the model to the best extent. Following the data science lifecycle for tuning, the model does not appear to overfit to the validation/development split. Thus, I believe that this final workflow has satisfied the requirements of this assignment. 💪"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3OWMVgfWtsg"
      },
      "source": [
        "# Task 5: Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISmyPVTwWwH5"
      },
      "source": [
        "**Q1. Why a simple linear regression model (without any activation function) is not good for classification task, compared to Perceptron/Logistic regression?**\n",
        "\n",
        "A1. In most cases, data is not linearly separable. Simple linear regression is only suitable for separating two-dimensional data, and usses only a line for the decision boundary. This does not work for higher dimensional data, which requires a more complex classifier such as SVM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNhueeeeXSBt"
      },
      "source": [
        "**Q2. What's a decision tree and how it is different to a logistic regression model?**\n",
        "\n",
        "A2. Decision trees split data into smaller subsets based on the values of certain features. This process reduces the full dataset until all data points belonging to a subset within one of the leaf nodes has the same answer. Logistic regression is different in that the predicted output is based on a function, and works well with continuous data. Both classifiers are similar as they are discriminative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9PDAMPFXSU2"
      },
      "source": [
        "**Q3. We discussed three variants of decision tree in our lecture, what are their differences?**\n",
        "\n",
        "A3. The three variants of decision tree that were discussed were ID3, C4.5, and CART. Differences are described below.\n",
        "\n",
        "ID3 uses information gain to decide which features to use to split the data first. Data is treated as categorical, deciding based on the number of different values that feature can take and the way the answers are separated among them. No pruning is done.\n",
        "\n",
        "C4.5 uses the gain ratio, which is a version of information gain with reduced bias towards high-branch attributes. This is done to achieve a more even distribution, however it may overcompensate due to its method of selection. Moreover, C4.5 deals better with noisy/unclean data, and can use both categorical and numeric attributes.\n",
        "\n",
        "CART uses GINI index to assess the likelihood of an attribute to be 'impure'. If an attribute has a wide range of answers compared to other attributes, then it is more likely to be considered impure and irrelevant to the classification. This is a more robust type of decision tree, as it can use both categorical and numeric attributes, as well as deal with both noisy and unclean data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC48aIiUXShM"
      },
      "source": [
        "**Q4. What is the difference between the random forest model, and a bagging ensemble of CART models?**\n",
        "\n",
        "A4. Random forest models use several decision trees, each with its own subset of features. On the contrary, a bagging ensemble of CART models uses the same model on a subset of the total dataset. Bagging uses all of the features, whereas random forest uses only a subset of the features in each decision tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6mR2iWPXS1Y"
      },
      "source": [
        "**Q5. How is gradient boosting different to boosting (adaboost)?**\n",
        "\n",
        "A5. Adaptive Boosting (AdaBoost) is the original boosting ensemble model, which uses several weak learners to form a strong learner. AdaBoost uses an exponential loss function, whereas Gradient Boosting can use any differentiable loss function. Gradient Boosting differs from AdaBoost in that it uses the negative gradient to indicate the direction of weight adjustments that should be made to reduce the magnitude of loss/error. In other words, gradient boosting creates weak learners by training on the residuals of the strong learner, which puts more weight on the more difficult training samples. The contribution of each weak learner to the strong learner is computed using gradient descent. AdaBoost differs in that it changes the weight attached to each training sample to encourage the weak learner to focus on the difficult training samples, and each weak learner is added to the strong learner according to the performance on the sample distribution."
      ]
    }
  ]
}